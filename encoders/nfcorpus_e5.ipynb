{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb91b09a",
   "metadata": {},
   "source": [
    "# Comparing Bi-Encoders and Cross-Encoders on Scifact Dataset\n",
    "**E5 Bi-Encoder, NFCorpus**\n",
    "\n",
    "This notebook shows how to:\n",
    "1. Load the nfcorpus dataset (corpus, queries, qrels)\n",
    "2. Perform bi-encoder retrieval using FAISS HNSW.\n",
    "3. Save or inspect intermediate variables (embeddings, top-k results).\n",
    "4. Rerank the top-k results with a cross-encoder.\n",
    "5. Compare the evaluations at each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbfef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\r\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\r\n",
      "0.00s - to python to disable frozen modules.\r\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\r\n",
      "Available kernels:\r\n",
      "  wse-env    /home/dl5214/.local/share/jupyter/kernels/wse-env\r\n",
      "  python3    /home/shaoyu/anaconda3/share/jupyter/kernels/python3\r\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Select the correct kernel\n",
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fa422",
   "metadata": {},
   "source": [
    "# Part I: Preparations\n",
    "1. Import packages.\n",
    "2. Load data.\n",
    "3. Prepare the queries for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc935e3",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl5214/.conda/envs/wse-env/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/dl5214/.conda/envs/wse-env/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Logging\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "import faiss\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59cb8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090e7adc",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Loading Functions\n",
    "def load_scifact_corpus(corpus_file):\n",
    "    \"\"\"\n",
    "    Loads the Scifact corpus from a JSONL file.\n",
    "    Each line is a JSON object containing '_id' and 'text'.\n",
    "    Returns lists of document IDs and document texts.\n",
    "    \"\"\"\n",
    "    doc_ids = []\n",
    "    doc_texts = []\n",
    "    with open(corpus_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            doc_id = data[\"_id\"]\n",
    "            text_str = data.get(\"text\", \"\")\n",
    "            doc_ids.append(doc_id)\n",
    "            doc_texts.append(text_str)\n",
    "    return doc_ids, doc_texts\n",
    "\n",
    "def load_scifact_queries(queries_file):\n",
    "    \"\"\"\n",
    "    Loads the Scifact queries from a JSONL file.\n",
    "    Each line is a JSON object containing '_id' and 'text'.\n",
    "    Returns lists of query IDs and query texts.\n",
    "    \"\"\"\n",
    "    q_ids = []\n",
    "    q_texts = []\n",
    "    with open(queries_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            q_ids.append(data[\"_id\"])\n",
    "            q_texts.append(data.get(\"text\", \"\"))\n",
    "    return q_ids, q_texts\n",
    "\n",
    "def load_qrels(qrels_file):\n",
    "    \"\"\"\n",
    "    Loads the qrels from a TSV file.\n",
    "    The first line is a header: 'query-id    corpus-id    score'.\n",
    "    Returns a dictionary: qrels[query_id][doc_id] = relevance_score.\n",
    "    \"\"\"\n",
    "    qrels = {}\n",
    "    with open(qrels_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        # Skip the header line:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            qid, did, rel = line.split()\n",
    "            rel = int(rel)\n",
    "            if qid not in qrels:\n",
    "                qrels[qid] = {}\n",
    "            qrels[qid][did] = rel\n",
    "    return qrels\n",
    "\n",
    "print('Data loading functions ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e456f24f",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Metric Evaluation Function\n",
    "# We'll define a single function we can call multiple times,\n",
    "# whether for the bi-encoder alone or after cross-encoder reranking.\n",
    "\n",
    "def evaluate_results(qrels, results, k_values=None):\n",
    "    \"\"\"\n",
    "    Evaluates retrieval results using pytrec_eval.\n",
    "    results: dict of dict => results[qid][doc_id] = score\n",
    "    qrels: dict of dict => qrels[qid][doc_id] = relevance\n",
    "    k_values: list of cutoff values (e.g. [5,10,20])\n",
    "    \"\"\"\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {\"map\", \"ndcg_cut\", \"recall\", \"P\"})\n",
    "    scores = evaluator.evaluate(results)\n",
    "\n",
    "    if k_values is None:\n",
    "        # If k_values not specified, use typical cutoffs\n",
    "        k_values = [5, 10, 20, 30, 100]\n",
    "\n",
    "    ndcg_res = {}\n",
    "    recall_res = {}\n",
    "    prec_res = {}\n",
    "    mrr_vals = []\n",
    "\n",
    "    # Compute mean average precision (MAP) across all queries\n",
    "    map_vals = [scores[qid][\"map\"] for qid in scores]\n",
    "    map_res = np.mean(map_vals)\n",
    "\n",
    "    # Compute NDCG@k, Recall@k, P@k\n",
    "    for k in k_values:\n",
    "        ndcg_vals = []\n",
    "        recall_vals = []\n",
    "        prec_vals = []\n",
    "        for qid in scores:\n",
    "            ndcg_key = f\"ndcg_cut_{k}\"\n",
    "            recall_key = f\"recall_{k}\"\n",
    "            prec_key = f\"P_{k}\"\n",
    "            # If the metric isn't found for some reason, skip\n",
    "            if ndcg_key in scores[qid]:\n",
    "                ndcg_vals.append(scores[qid][ndcg_key])\n",
    "            if recall_key in scores[qid]:\n",
    "                recall_vals.append(scores[qid][recall_key])\n",
    "            if prec_key in scores[qid]:\n",
    "                prec_vals.append(scores[qid][prec_key])\n",
    "\n",
    "        ndcg_res[f\"NDCG@{k}\"] = np.mean(ndcg_vals) if ndcg_vals else 0.0\n",
    "        recall_res[f\"Recall@{k}\"] = np.mean(recall_vals) if recall_vals else 0.0\n",
    "        prec_res[f\"P@{k}\"] = np.mean(prec_vals) if prec_vals else 0.0\n",
    "\n",
    "    # Compute MRR (Mean Reciprocal Rank)\n",
    "    for qid in results:\n",
    "        ranked_docs = sorted(results[qid].items(), key=lambda x: x[1], reverse=True)\n",
    "        for rank, (doc_id, _) in enumerate(ranked_docs, start=1):\n",
    "            if qrels.get(qid, {}).get(doc_id, 0) > 0:  # Relevant document\n",
    "                mrr_vals.append(1 / rank)\n",
    "                break\n",
    "        else:\n",
    "            mrr_vals.append(0)  # No relevant document found in results\n",
    "\n",
    "    mrr_res = np.mean(mrr_vals)\n",
    "\n",
    "    return ndcg_res, map_res, recall_res, prec_res, mrr_res\n",
    "\n",
    "print('Evaluation function ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021a8164",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3633 documents and 3237 queries.\n",
      "Unique qrels: 323\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load the SciFact Data\n",
    "corpus_file = \"datasets/nfcorpus/corpus.jsonl\"\n",
    "queries_file = \"datasets/nfcorpus/queries.jsonl\"\n",
    "qrels_file = \"datasets/nfcorpus/qrels/test.tsv\"\n",
    "\n",
    "doc_ids, doc_texts = load_scifact_corpus(corpus_file)\n",
    "query_ids, query_texts = load_scifact_queries(queries_file)\n",
    "qrels = load_qrels(qrels_file)\n",
    "\n",
    "print(f\"Loaded {len(doc_ids)} documents and {len(query_ids)} queries.\")\n",
    "print(f\"Unique qrels: {len(qrels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef59d33",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered queries for evaluation: 323\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Filter queries to those that appear in qrels\n",
    "filtered_query_ids = [qid for qid in query_ids if qid in qrels]\n",
    "filtered_query_texts = [query_texts[query_ids.index(qid)] for qid in filtered_query_ids]\n",
    "\n",
    "print(f\"Filtered queries for evaluation: {len(filtered_query_ids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1f349",
   "metadata": {},
   "source": [
    "# Part II: Bi-Encoder Retrieval with FAISS HNSW\n",
    "\n",
    "We'll:\n",
    "1. Load a SentenceTransformer (E5) model.\n",
    "2. Encode all documents with prefix **\"passage: \"**.\n",
    "3. Build a FAISS HNSW index.\n",
    "4. Encode queries with prefix **\"query: \"**.\n",
    "5. Perform approximate nearest neighbor (ANN) search.\n",
    "6. Evaluate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9c53ed",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Bi-Encoder model loaded on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Bi-Encoder Setup\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "# Set the device to \"cuda\" if available, otherwise fallback to \"cpu\"\n",
    "device = \"cuda\" if cuda_available else \"cpu\"\n",
    "\n",
    "# Load the Bi-Encoder model on the specified device\n",
    "bi_model = SentenceTransformer(\"intfloat/e5-base-v2\", device=device)\n",
    "print(f\"Bi-Encoder model loaded on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15acb6a9",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8711350964e64802832ae6119853be67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus embeddings shape: (3633, 768)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Encode Corpus with E5 (prefix 'passage: ')\n",
    "# We'll store these embeddings in a variable so we can reuse or inspect them.\n",
    "corpus_embeddings = bi_model.encode([\n",
    "    \"passage: \" + text for text in doc_texts\n",
    "],\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "print(\"Corpus embeddings shape:\", corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2168fbeb",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building HNSW index...\n",
      "INFO:root:Moving HNSW index to GPU...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSW index ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Build the FAISS HNSW Index\n",
    "dimension = corpus_embeddings.shape[1]\n",
    "M = 15  # number of connections per node in HNSW\n",
    "efConstruction = 300\n",
    "efSearch = 1000\n",
    "\n",
    "logging.info(\"Building HNSW index...\")\n",
    "index_hnsw = faiss.IndexHNSWFlat(dimension, M)\n",
    "index_hnsw.hnsw.efConstruction = efConstruction\n",
    "index_hnsw.hnsw.efSearch = efSearch\n",
    "\n",
    "# Add corpus embeddings to index\n",
    "index_hnsw.add(corpus_embeddings)\n",
    "\n",
    "# If GPU available, move index to GPU\n",
    "if torch.cuda.is_available():\n",
    "    logging.info(\"Moving HNSW index to GPU...\")\n",
    "    faiss_res = faiss.StandardGpuResources()\n",
    "    index_hnsw = faiss.index_cpu_to_gpu(faiss_res, 0, index_hnsw)\n",
    "\n",
    "print(\"HNSW index ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "275bd6fb",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587072bee73b4f45b91a81f7b26db4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embeddings shape: (323, 768)\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Encode Queries with E5 (prefix 'query: ')\n",
    "# We'll store query embeddings so we can re-run or examine.\n",
    "\n",
    "query_embeddings = bi_model.encode([\n",
    "    \"query: \" + text for text in filtered_query_texts\n",
    "],\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "print(\"Query embeddings shape:\", query_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36832a0",
   "metadata": {},
   "source": [
    "## Perform ANN Search and Evaluate (Bi-Encoder Only)\n",
    "\n",
    "We'll retrieve the top-k docs from FAISS for each query, then convert them to a `results` dict for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3f9a84",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Searching query embeddings in HNSW index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-Encoder top-k results ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Bi-Encoder ANN Search\n",
    "top_k = 500\n",
    "logging.info(\"Searching query embeddings in HNSW index...\")\n",
    "D, I = index_hnsw.search(query_embeddings, top_k)\n",
    "\n",
    "# Convert results to pytrec_eval format\n",
    "# results[qid][docid] = score\n",
    "bi_encoder_results = {}\n",
    "for q_idx, qid in enumerate(filtered_query_ids):\n",
    "    bi_encoder_results[qid] = {}\n",
    "    for rank in range(top_k):\n",
    "        doc_idx = I[q_idx, rank]\n",
    "        # for a distance D[q_idx, rank], we can invert or just use negative distance\n",
    "        # Some prefer 1/dist, or -dist, or use it directly.\n",
    "        # We'll do a small trick: score = 1 / distance.\n",
    "        # If distance is 0, we can handle that or set a high value.\n",
    "        dist = D[q_idx, rank]\n",
    "        score = 1/float(dist) if dist != 0 else 1e9\n",
    "        doc_id = doc_ids[doc_idx]\n",
    "        bi_encoder_results[qid][doc_id] = score\n",
    "\n",
    "print(\"Bi-Encoder top-k results ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518b7f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query Results ===\n",
      "Query ID: PLAIN-2\n",
      "Number of retrieved documents: 500\n",
      "Scores (truncated): {'MED-14': 4.237087193482339, 'MED-10': 3.8247778673211057, 'MED-2431': 3.6305412946845186\n",
      "--------------------------------------------------\n",
      "Query ID: PLAIN-12\n",
      "Number of retrieved documents: 500\n",
      "Scores (truncated): {'MED-2514': 3.4046419789163305, 'MED-2512': 3.1757043666839833, 'MED-2510': 3.01602271776\n",
      "--------------------------------------------------\n",
      "Query ID: PLAIN-23\n",
      "Number of retrieved documents: 500\n",
      "Scores (truncated): {'MED-2651': 3.2320151278784253, 'MED-118': 3.2320151278784253, 'MED-2658': 3.173684390732\n",
      "--------------------------------------------------\n",
      "Query ID: PLAIN-33\n",
      "Number of retrieved documents: 500\n",
      "Scores (truncated): {'MED-2723': 3.3794334601905467, 'MED-2717': 3.3142183013926374, 'MED-5006': 3.17065579494\n",
      "--------------------------------------------------\n",
      "Query ID: PLAIN-44\n",
      "Number of retrieved documents: 500\n",
      "Scores (truncated): {'MED-2791': 3.8944263553889304, 'MED-2814': 3.8365978411325465, 'MED-2809': 3.73611856194\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the number of retrieved documents for the first 5 queries along with their scores\n",
    "print(\"=== Query Results ===\")\n",
    "for query_id, doc_scores in list(bi_encoder_results.items())[:5]:  # Limit to first 5 queries\n",
    "    num_docs = len(doc_scores)  # Number of documents retrieved for this query\n",
    "    print(f\"Query ID: {query_id}\")\n",
    "    print(f\"Number of retrieved documents: {num_docs}\")\n",
    "    print(f\"Scores (truncated): {str(doc_scores)[:90]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0376a3a",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bi-Encoder (E5) Results ===\n",
      "NDCG@k:\n",
      "  NDCG@5 : 0.3675\n",
      "  NDCG@10: 0.3431\n",
      "  NDCG@20: 0.3230\n",
      "  NDCG@30: 0.3131\n",
      "  NDCG@100: 0.3163\n",
      "\n",
      "MAP: 0.1676\n",
      "\n",
      "Recall@k:\n",
      "  Recall@5: 0.1256\n",
      "  Recall@10: 0.1665\n",
      "  Recall@20: 0.2081\n",
      "  Recall@30: 0.2292\n",
      "  Recall@100: 0.3224\n",
      "\n",
      "Precision@k:\n",
      "  P@5     : 0.3152\n",
      "  P@10    : 0.2560\n",
      "  P@20    : 0.1923\n",
      "  P@30    : 0.1563\n",
      "  P@100   : 0.0814\n",
      "\n",
      "MRR: 0.5532\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Evaluate Bi-Encoder Results\n",
    "k_values = [5, 10, 20, 30, 100]\n",
    "ndcg_bi, map_bi, recall_bi, prec_bi, mrr_bi = evaluate_results(qrels, bi_encoder_results, k_values)\n",
    "\n",
    "print(\"=== Bi-Encoder (E5) Results ===\")\n",
    "# print(\"NDCG@k:\", ndcg_bi)\n",
    "# print(\"MAP:\", map_bi)\n",
    "# print(\"Recall@k:\", recall_bi)\n",
    "# print(\"Precision@k:\", prec_bi)\n",
    "print(\"NDCG@k:\")\n",
    "for k, v in ndcg_bi.items():\n",
    "    print(f\"  {k:<7}: {v:.4f}\")\n",
    "\n",
    "print(f\"\\nMAP: {map_bi:.4f}\")\n",
    "\n",
    "print(\"\\nRecall@k:\")\n",
    "for k, v in recall_bi.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nPrecision@k:\")\n",
    "for k, v in prec_bi.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")\n",
    "    \n",
    "print(f\"\\nMRR: {mrr_bi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92333d1d",
   "metadata": {},
   "source": [
    "# Part III: Cross-Encoder Reranking\n",
    "\n",
    "We'll now demonstrate how to:\n",
    "1. Take the **top-k** documents from the **bi-encoder** results.\n",
    "2. Rerank them with a **CrossEncoder**.\n",
    "3. Evaluate again using the same `evaluate_results` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e022653",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder rerank function defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Define a function to rerank with a CrossEncoder\n",
    "\n",
    "def cross_encode_rerank(cross_encoder_model, \n",
    "                        query_ids_list, query_texts_list,\n",
    "                        topk_results, corpus_text_map,\n",
    "                        rerank_top_k=500, final_top_k=100):\n",
    "    \"\"\"\n",
    "    cross_encoder_model: a CrossEncoder from sentence-transformers\n",
    "    query_ids_list: list of query IDs (strings)\n",
    "    query_texts_list: list of corresponding query texts\n",
    "    topk_results: dict => topk_results[qid][doc_id] = some bi-encoder score\n",
    "    corpus_text_map: a dict doc_id -> doc_text\n",
    "    rerank_top_k: how many documents to consider for reranking from the bi-encoder results\n",
    "    final_top_k: how many documents to keep after cross-encoder reranking\n",
    "\n",
    "    returns: dict => reranked_results[qid][doc_id] = cross-encoder score\n",
    "    \"\"\"\n",
    "    reranked_results = {}\n",
    "\n",
    "    # Use tqdm to show total progress for all queries\n",
    "    with tqdm(total=len(query_ids_list), desc=\"Cross-encoding queries\", unit=\"query\", ncols=80) as pbar:\n",
    "        for idx, qid in enumerate(query_ids_list):\n",
    "            # Get top rerank_top_k document candidates for the query\n",
    "            doc_candidates = sorted(topk_results[qid].items(), key=lambda x: x[1], reverse=True)[:rerank_top_k]\n",
    "            doc_ids = [doc_id for doc_id, _ in doc_candidates]\n",
    "            query_text = query_texts_list[idx]\n",
    "\n",
    "            # Prepare query-document pairs for the cross-encoder\n",
    "#             pair_texts = [(f\"query: {query_text}\", f\"passage: {corpus_text_map[doc_id]}\") for doc_id in doc_ids]\n",
    "            pair_texts = [(query_text, corpus_text_map[doc_id]) for doc_id in doc_ids]\n",
    "            \n",
    "            # Perform cross-encoder inference, ensure no additional progress bars are shown\n",
    "            scores = cross_encoder_model.predict(pair_texts, show_progress_bar=False)\n",
    "\n",
    "            # Combine document IDs with their Cross-Encoder scores\n",
    "            reranked_doc_scores = {doc_ids[i]: float(scores[i]) for i in range(len(doc_ids))}\n",
    "\n",
    "            # Sort reranked results by Cross-Encoder scores and keep final_top_k\n",
    "            reranked_results[qid] = dict(sorted(reranked_doc_scores.items(), key=lambda x: x[1], reverse=True)[:final_top_k])\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    return reranked_results\n",
    "\n",
    "print('Cross-encoder rerank function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc70c7",
   "metadata": {},
   "source": [
    "### Prepare Data Structures for Reranking\n",
    "\n",
    "- We already have `bi_encoder_results`, which is `dict[qid][doc_id] = score`.\n",
    "- We need a quick way to map doc IDs to actual text for the CrossEncoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb81cd38",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_id_to_text dictionary has 3633 entries.\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Create a dictionary doc_id -> doc_text\n",
    "doc_id_to_text = {}\n",
    "for i, did in enumerate(doc_ids):\n",
    "    doc_id_to_text[did] = doc_texts[i]\n",
    "\n",
    "print(f\"doc_id_to_text dictionary has {len(doc_id_to_text)} entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33951921",
   "metadata": {},
   "source": [
    "## 3.1: MiniLM CrossEncoder Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e642f9",
   "metadata": {},
   "source": [
    "### Load a CrossEncoder\n",
    "Choose any cross-encoder checkpoint from Hugging Face or sentence-transformers.\n",
    "For demonstration, we'll pick something like `'cross-encoder/ms-marco-MiniLM-L-6-v2'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "039567e0",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEncoder loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: CrossEncoder initialization\n",
    "cross_model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"  # or any other suitable model\n",
    "cross_encoder = CrossEncoder(cross_model_name, device=device)\n",
    "print(\"CrossEncoder loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7e047",
   "metadata": {},
   "source": [
    "### Rerank the top-k results from the Bi-Encoder\n",
    "\n",
    "We'll use the cross-encoder function defined above and pass in the top-k results from the Bi-Encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "238a2dd5",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reranking top 300 candidates with cross-encoder, keeping top 100...\n",
      "Cross-encoding queries: 100%|██████████████| 323/323 [06:53<00:00,  1.28s/query]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder reranking complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Rerank top-k with CrossEncoder\n",
    "\n",
    "# Parameters to control the number of documents to rerank and return\n",
    "rerank_top_k = 300  # Number of documents to consider for reranking\n",
    "final_top_k = 100    # Number of documents to keep after reranking\n",
    "\n",
    "logging.info(f\"Reranking top {rerank_top_k} candidates with cross-encoder, keeping top {final_top_k}...\")\n",
    "\n",
    "cross_encoder_results_minilm = cross_encode_rerank(\n",
    "    cross_encoder_model=cross_encoder,\n",
    "    query_ids_list=filtered_query_ids,\n",
    "    query_texts_list=filtered_query_texts,\n",
    "    topk_results=bi_encoder_results,  # Bi-Encoder results\n",
    "    corpus_text_map=doc_id_to_text,   # Document text mapping\n",
    "    rerank_top_k=rerank_top_k,        # Candidates to rerank\n",
    "    final_top_k=final_top_k           # Final results to keep\n",
    ")\n",
    "\n",
    "print(\"Cross-encoder reranking complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca8420",
   "metadata": {},
   "source": [
    "### Evaluate Cross-Encoder Reranked Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1281eedb",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MiniLM Cross-Encoder (Rerank) Results ===\n",
      "NDCG@k:\n",
      "  NDCG@5 : 0.3794\n",
      "  NDCG@10: 0.3405\n",
      "  NDCG@20: 0.3153\n",
      "  NDCG@30: 0.3060\n",
      "  NDCG@100: 0.3071\n",
      "\n",
      "MAP: 0.1570\n",
      "\n",
      "Recall@k:\n",
      "  Recall@5: 0.1315\n",
      "  Recall@10: 0.1600\n",
      "  Recall@20: 0.1915\n",
      "  Recall@30: 0.2095\n",
      "  Recall@100: 0.2878\n",
      "\n",
      "Precision@k:\n",
      "  P@5     : 0.3189\n",
      "  P@10    : 0.2418\n",
      "  P@20    : 0.1785\n",
      "  P@30    : 0.1479\n",
      "  P@100   : 0.0775\n",
      "\n",
      "MRR: 0.5684\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Evaluate the cross-encoder-based results\n",
    "k_values = [5, 10, 20, 30, 100]\n",
    "ndcg_ce, map_ce, recall_ce, prec_ce, mrr_ce = evaluate_results(qrels, cross_encoder_results_minilm, k_values)\n",
    "\n",
    "# print(\"=== Cross-Encoder (Rerank) Results ===\")\n",
    "# print(\"NDCG@k:\", ndcg_ce)\n",
    "# print(\"MAP:\", map_ce)\n",
    "# print(\"Recall@k:\", recall_ce)\n",
    "# print(\"Precision@k:\", prec_ce)\n",
    "\n",
    "# Print formatted results\n",
    "print(\"=== MiniLM Cross-Encoder (Rerank) Results ===\")\n",
    "print(\"NDCG@k:\")\n",
    "for k, v in ndcg_ce.items():\n",
    "    print(f\"  {k:<7}: {v:.4f}\")\n",
    "\n",
    "print(f\"\\nMAP: {map_ce:.4f}\")\n",
    "\n",
    "print(\"\\nRecall@k:\")\n",
    "for k, v in recall_ce.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nPrecision@k:\")\n",
    "for k, v in prec_ce.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")\n",
    "    \n",
    "print(f\"\\nMRR: {mrr_ce:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a95c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7e3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a532381f",
   "metadata": {},
   "source": [
    "## 3.2: Electra CrossEncoder Reranking\n",
    "To compare the performance of different cross-encoders, here we use `'cross-encoder/ms-marco-electra-base'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "127e8f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEncoder loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: CrossEncoder initialization\n",
    "cross_model_name = \"cross-encoder/ms-marco-electra-base\"  # or any other suitable model\n",
    "cross_encoder = CrossEncoder(cross_model_name, device=device)\n",
    "print(\"CrossEncoder loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75bcb541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reranking top 300 candidates with cross-encoder, keeping top 100...\n",
      "Cross-encoding queries: 100%|██████████████| 323/323 [49:04<00:00,  9.12s/query]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder reranking complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Rerank top-k with CrossEncoder\n",
    "\n",
    "# Parameters to control the number of documents to rerank and return\n",
    "rerank_top_k = 300  # Number of documents to consider for reranking\n",
    "final_top_k = 100    # Number of documents to keep after reranking\n",
    "\n",
    "logging.info(f\"Reranking top {rerank_top_k} candidates with cross-encoder, keeping top {final_top_k}...\")\n",
    "\n",
    "cross_encoder_results_electra = cross_encode_rerank(\n",
    "    cross_encoder_model=cross_encoder,\n",
    "    query_ids_list=filtered_query_ids,\n",
    "    query_texts_list=filtered_query_texts,\n",
    "    topk_results=bi_encoder_results,  # Bi-Encoder results\n",
    "    corpus_text_map=doc_id_to_text,   # Document text mapping\n",
    "    rerank_top_k=rerank_top_k,        # Candidates to rerank\n",
    "    final_top_k=final_top_k           # Final results to keep\n",
    ")\n",
    "\n",
    "print(\"Cross-encoder reranking complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91efbbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Electra Cross-Encoder (Rerank) Results ===\n",
      "NDCG@k:\n",
      "  NDCG@5 : 0.3240\n",
      "  NDCG@10: 0.2903\n",
      "  NDCG@20: 0.2699\n",
      "  NDCG@30: 0.2613\n",
      "  NDCG@100: 0.2696\n",
      "\n",
      "MAP: 0.1277\n",
      "\n",
      "Recall@k:\n",
      "  Recall@5: 0.1148\n",
      "  Recall@10: 0.1396\n",
      "  Recall@20: 0.1719\n",
      "  Recall@30: 0.1867\n",
      "  Recall@100: 0.2735\n",
      "\n",
      "Precision@k:\n",
      "  P@5     : 0.2799\n",
      "  P@10    : 0.2099\n",
      "  P@20    : 0.1531\n",
      "  P@30    : 0.1254\n",
      "  P@100   : 0.0692\n",
      "\n",
      "MRR: 0.5036\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Evaluate the cross-encoder-based results\n",
    "k_values = [5, 10, 20, 30, 100]\n",
    "ndcg_ce, map_ce, recall_ce, prec_ce, mrr_ce = evaluate_results(qrels, cross_encoder_results_electra, k_values)\n",
    "\n",
    "# print(\"=== Cross-Encoder (Rerank) Results ===\")\n",
    "# print(\"NDCG@k:\", ndcg_ce)\n",
    "# print(\"MAP:\", map_ce)\n",
    "# print(\"Recall@k:\", recall_ce)\n",
    "# print(\"Precision@k:\", prec_ce)\n",
    "\n",
    "# Print formatted results\n",
    "print(\"=== Electra Cross-Encoder (Rerank) Results ===\")\n",
    "print(\"NDCG@k:\")\n",
    "for k, v in ndcg_ce.items():\n",
    "    print(f\"  {k:<7}: {v:.4f}\")\n",
    "\n",
    "print(f\"\\nMAP: {map_ce:.4f}\")\n",
    "\n",
    "print(\"\\nRecall@k:\")\n",
    "for k, v in recall_ce.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nPrecision@k:\")\n",
    "for k, v in prec_ce.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")\n",
    "    \n",
    "print(f\"\\nMRR: {mrr_ce:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe0816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5923b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91ed4856",
   "metadata": {},
   "source": [
    "## 3.3: DeBERTa CrossEncoder Reranking\n",
    "To compare the performance of different cross-encoders, here we use `'cross-encoder/ms-marco-Microsoft/DeBERTa-V3-Large'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b54220e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:1633\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1632\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTikTokenConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:1533\u001b[0m, in \u001b[0;36mTikTokenConverter.converted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconverted\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tokenizer:\n\u001b[0;32m-> 1533\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1534\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m pre_tokenizers\u001b[38;5;241m.\u001b[39mSequence(\n\u001b[1;32m   1535\u001b[0m         [\n\u001b[1;32m   1536\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mSplit(Regex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), behavior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated\u001b[39m\u001b[38;5;124m\"\u001b[39m, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1537\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mByteLevel(add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space, use_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1538\u001b[0m         ]\n\u001b[1;32m   1539\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:1526\u001b[0m, in \u001b[0;36mTikTokenConverter.tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1526\u001b[0m     vocab_scores, merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_vocab_merges_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1527\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(BPE(vocab_scores, merges, fuse_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:1502\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tiktoken` is required to read a `tiktoken` file. Install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1500\u001b[0m     )\n\u001b[0;32m-> 1502\u001b[0m bpe_ranks \u001b[38;5;241m=\u001b[39m \u001b[43mload_tiktoken_bpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtiktoken_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1503\u001b[0m byte_encoder \u001b[38;5;241m=\u001b[39m bytes_to_unicode()\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/tiktoken/load.py:144\u001b[0m, in \u001b[0;36mload_tiktoken_bpe\u001b[0;34m(tiktoken_bpe_file, expected_hash)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tiktoken_bpe\u001b[39m(tiktoken_bpe_file: \u001b[38;5;28mstr\u001b[39m, expected_hash: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# NB: do not add caching to this function\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     contents \u001b[38;5;241m=\u001b[39m \u001b[43mread_file_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtiktoken_bpe_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hash\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    146\u001b[0m         base64\u001b[38;5;241m.\u001b[39mb64decode(token): \u001b[38;5;28mint\u001b[39m(rank)\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m token, rank \u001b[38;5;129;01min\u001b[39;00m (line\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m contents\u001b[38;5;241m.\u001b[39msplitlines() \u001b[38;5;28;01mif\u001b[39;00m line)\n\u001b[1;32m    148\u001b[0m     }\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/tiktoken/load.py:48\u001b[0m, in \u001b[0;36mread_file_cached\u001b[0;34m(blobpath, expected_hash)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_file(blobpath)\n\u001b[0;32m---> 48\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39msha1(\u001b[43mblobpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m())\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[1;32m     50\u001b[0m cache_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cache_dir, cache_key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'encode'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 14: CrossEncoder initialization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cross_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/deberta-v3-large\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# or any other suitable model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cross_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mCrossEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:113\u001b[0m, in \u001b[0;36mCrossEncoder.__init__\u001b[0;34m(self, model_name, num_labels, max_length, device, automodel_args, tokenizer_args, config_args, cache_dir, trust_remote_code, revision, local_files_only, default_activation_function, classifier_dropout)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m=\u001b[39m num_labels\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    105\u001b[0m     model_name,\n\u001b[1;32m    106\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mautomodel_args,\n\u001b[1;32m    112\u001b[0m )\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m max_length\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:940\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2032\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2030\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2040\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2272\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2272\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[1;32m   2274\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2277\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2_fast.py:103\u001b[0m, in \u001b[0;36mDebertaV2TokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, do_lower_case, split_by_punct, bos_token, eos_token, unk_token, sep_token, pad_token, cls_token, mask_token, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     90\u001b[0m     vocab_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_lower_case\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_lower_case\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43msep_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_by_punct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_by_punct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_by_punct \u001b[38;5;241m=\u001b[39m split_by_punct\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:138\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m--> 138\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tiktoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/wse-env/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:1638\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TikTokenConverter(\n\u001b[1;32m   1634\u001b[0m         vocab_file\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39mvocab_file,\n\u001b[1;32m   1635\u001b[0m         additional_special_tokens\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39madditional_special_tokens,\n\u001b[1;32m   1636\u001b[0m     )\u001b[38;5;241m.\u001b[39mconverted()\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1639\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a SentencePiece tokenizer.model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently available slow->fast convertors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1642\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']"
     ]
    }
   ],
   "source": [
    "# Cell 14: CrossEncoder initialization\n",
    "cross_model_name = \"microsoft/deberta-v3-large\"  # or any other suitable model\n",
    "cross_encoder = CrossEncoder(cross_model_name, device=device)\n",
    "print(\"CrossEncoder loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Rerank top-k with CrossEncoder\n",
    "\n",
    "# Parameters to control the number of documents to rerank and return\n",
    "rerank_top_k = 300  # Number of documents to consider for reranking\n",
    "final_top_k = 100    # Number of documents to keep after reranking\n",
    "\n",
    "logging.info(f\"Reranking top {rerank_top_k} candidates with cross-encoder, keeping top {final_top_k}...\")\n",
    "\n",
    "cross_encoder_results_deberta = cross_encode_rerank(\n",
    "    cross_encoder_model=cross_encoder,\n",
    "    query_ids_list=filtered_query_ids,\n",
    "    query_texts_list=filtered_query_texts,\n",
    "    topk_results=bi_encoder_results,  # Bi-Encoder results\n",
    "    corpus_text_map=doc_id_to_text,   # Document text mapping\n",
    "    rerank_top_k=rerank_top_k,        # Candidates to rerank\n",
    "    final_top_k=final_top_k           # Final results to keep\n",
    ")\n",
    "\n",
    "print(\"Cross-encoder reranking complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c902e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Evaluate the cross-encoder-based results\n",
    "k_values = [5, 10, 20, 30, 100]\n",
    "ndcg_ce, map_ce, recall_ce, prec_ce = evaluate_results(qrels, cross_encoder_results, k_values)\n",
    "\n",
    "# print(\"=== Cross-Encoder (Rerank) Results ===\")\n",
    "# print(\"NDCG@k:\", ndcg_ce)\n",
    "# print(\"MAP:\", map_ce)\n",
    "# print(\"Recall@k:\", recall_ce)\n",
    "# print(\"Precision@k:\", prec_ce)\n",
    "\n",
    "# Print formatted results\n",
    "print(\"=== Electra Cross-Encoder (Rerank) Results ===\")\n",
    "print(\"NDCG@k:\")\n",
    "for k, v in ndcg_ce.items():\n",
    "    print(f\"  {k:<7}: {v:.4f}\")\n",
    "\n",
    "print(f\"\\nMAP: {map_ce:.4f}\")\n",
    "\n",
    "print(\"\\nRecall@k:\")\n",
    "for k, v in recall_ce.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nPrecision@k:\")\n",
    "for k, v in prec_ce.items():\n",
    "    print(f\"  {k:<8}: {v:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wse-env)",
   "language": "python",
   "name": "wse-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
